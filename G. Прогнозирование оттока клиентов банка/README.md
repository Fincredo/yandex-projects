# Прогнозирование оттока клиентов банка

_Модуль "Обучение с учителем"_


## Задача проекта

Взяв за основу исторические данные о поведении клиентов и расторжении договоров с банком, построить модель, способную спрогнозировать уход клиента из банка в ближайшее время.


## Описание проекта

Из «Бета-Банка» каждый месяц, немного, но заметно, стали уходить клиенты. По подсчетам банковских маркетологов, сохранять текущих клиентов дешевле, чем привлекать новых.  
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет.  
Для исследования предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.  
Необходимо построить модель с предельно большим значением F1-меры (не менее 0.59), а также измерять AUC-ROC, сравнивая ее значение с F1-мерой.


## Этапы работы

1.  Подготовка данных (пропуски, аномалии, дубликаты, корреляции).
2.  Предобработка данных:
    - переименование столбцов;
    - заполнение пропусков.
3.  Исследование задачи:
    - выделение признаков и разбивка на 3 выборки;
    - обучение без масштабирования;
    - обучение без учета балансов.
4.  Борьба с дисбалансом:
    - взвешивание классов;
    - увеличение выборки;
    - уменьшение выборки;
    - изменение порога классификации.
5.  Тестирование модели и проверка на адекватность.
6.  Общие выводы.


## Результат

1. Проведено первичное обучение моделей LogisticRegression, DecisionTreeClassifier и RandomForestClassifier на немасштабированных данных. Значения F1-меры составили: LR - 0.10, DT - 0.55, RF - 0.57. 
2. Произведено масштабирование количественных признаков путем их стандартизации. Проведено вторичное обучение моделей. Значения F1-меры составили: LR - 0.30, DT - 0.55, RF - 0.57.
3. Проведено еще 4 цикла обучения моделей тех же трех структур, но уже с учетом дисбаланса. Примененные подходы (взвешивание классов, upsampling, downsampling, изменение порога) дали следующие значения F1-меры: LR - от 0.47 до 0.49, DT - от 0.55 до 0.57, RF - от 0.57 до 0.62. Лучшими оказались модели RandomForestClassifier: сбалансированная, с увеличенной выборкой и с регулировкой порога. 
4. Наиболее высокое качество при проверке на тестовой выборке продемонстрировала модель классификатора случайного леса с регулировкой порога. Значение F1-меры составило более 0.63, AUC-ROC - 0.87.
5. Проверку адекватности через сравнение с результатами константных и случайных моделей структуры DummyClassifier модель прошла успешно. 


## Библиотеки и методы

- Python
- pandas
- numpy
- seaborn
- matplotlib
- sklearn
- re
- random
- AUC-ROC
- Confusion Matrix
- TPR/FPR
- OHE
- Стандартизация
